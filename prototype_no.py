from skimage.metrics import structural_similarity as ssim
from torchvision import models, transforms
import torch
import os
import cv2
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm
import cupy as cp
import spams

print("PyTorch ç‰ˆæœ¬:", torch.__version__)
print("CUDA æ˜¯å¦å¯ç”¨:", torch.cuda.is_available())
print("å½“å‰è®¾å¤‡:", torch.device("cuda" if torch.cuda.is_available() else "cpu"))
print("å½“å‰è®¾å¤‡ ID:", cp.cuda.Device().id)
print("å¯ç”¨è®¾å¤‡æ•°é‡:", cp.cuda.runtime.getDeviceCount())


class TissueMaskException(Exception):
    pass


def get_tissue_mask(ImgInput, luminosity_threshold=0.8):
    """ç”Ÿæˆç»„ç»‡æ©ç """
    if isinstance(ImgInput, cp.ndarray):
        ImgInput = cp.asnumpy(ImgInput)
    Img_LAB = cv2.cvtColor(ImgInput, cv2.COLOR_RGB2LAB)
    L = Img_LAB[:, :, 0] / 255.0
    mask = L < luminosity_threshold
    if mask.sum() == 0:
        raise TissueMaskException("Empty tissue mask computed")
    return mask


def convert_RGB_to_OD(I):
    """RGBè½¬å…‰å­¦å¯†åº¦ç©ºé—´"""
    I = cp.maximum(I, 1)  # é˜²æ­¢log(0)
    return -cp.log(I / 255.0)


def convert_OD_to_RGB(OD):
    """å…‰å­¦å¯†åº¦è½¬RGB"""
    return (255 * cp.exp(-OD)).astype(cp.uint8)


def normalize_matrix_rows(A):
    """è¡Œå½’ä¸€åŒ–"""
    return A / cp.linalg.norm(A, axis=1)[:, None]


def get_stain_matrix(ImgInput, luminosity_threshold=0.8, angular_percentile=99):
    """è·å–æŸ“è‰²çŸ©é˜µ"""
    if isinstance(ImgInput, np.ndarray):
        ImgInput = cp.array(ImgInput)

    tissue_mask = get_tissue_mask(ImgInput, luminosity_threshold)
    OD = convert_RGB_to_OD(ImgInput).reshape((-1, 3))
    OD = OD[tissue_mask.ravel()]

    # ä¸»æˆåˆ†åˆ†æ
    cov = cp.cov(OD, rowvar=False)
    _, V = cp.linalg.eigh(cov)
    V = V[:, [2, 1]]  # å–æœ€åä¸¤ä¸ªç‰¹å¾å‘é‡

    # è°ƒæ•´æ–¹å‘
    if V[0, 0] < 0: V[:, 0] *= -1
    if V[0, 1] < 0: V[:, 1] *= -1

    # è§’åº¦åˆ†å¸ƒåˆ†æ
    That = cp.dot(OD, V)
    phi = cp.arctan2(That[:, 1], That[:, 0])

    min_phi = cp.percentile(phi, 100 - angular_percentile)
    max_phi = cp.percentile(phi, angular_percentile)

    v1 = cp.dot(V, cp.array([cp.cos(min_phi), cp.sin(min_phi)]))
    v2 = cp.dot(V, cp.array([cp.cos(max_phi), cp.sin(max_phi)]))

    # ç¡®å®šæŸ“è‰²é¡ºåº
    HE = cp.array([v1, v2]) if v1[0] > v2[0] else cp.array([v2, v1])
    return normalize_matrix_rows(HE)


def get_concentrations(I, stain_matrix, regularizer=0.01):
    OD = convert_RGB_to_OD(I).reshape((-1, 3))
    OD = cp.asnumpy(OD)
    stain_matrix = cp.asnumpy(stain_matrix)
    result = spams.lasso(X=OD.T, D=stain_matrix.T, mode=2, lambda1=regularizer, pos=True).toarray().T
    result = cp.array(result)
    return result


def macenko_normalize(source, target, luminosity_threshold=0.8, angular_percentile=99):
    """
    Macenkoé¢œè‰²å½’ä¸€åŒ–æ ¸å¿ƒå‡½æ•°

    Args:
        source: å‚è€ƒå›¾åƒ (RGBæ ¼å¼)
        target: å¾…æ ‡å‡†åŒ–çš„ç›®æ ‡å›¾åƒ (RGBæ ¼å¼)

    Returns:
        å½’ä¸€åŒ–åçš„RGBå›¾åƒ (numpyæ•°ç»„)
    """
    # ç¡®ä¿è¾“å…¥æ˜¯cupyæ•°ç»„
    source_cp = cp.array(source) if isinstance(source, np.ndarray) else source
    target_cp = cp.array(target) if isinstance(target, np.ndarray) else target

    # è·å–æŸ“è‰²çŸ©é˜µï¼ˆä½¿ç”¨å‚è€ƒå›¾åƒï¼‰
    stain_matrix = get_stain_matrix(source_cp, luminosity_threshold, angular_percentile)

    # è®¡ç®—ç›®æ ‡å›¾åƒçš„æµ“åº¦
    concentrations = get_concentrations(target_cp, stain_matrix)

    # é‡å»ºå›¾åƒï¼ˆä½¿ç”¨å‚è€ƒå›¾åƒçš„æŸ“è‰²çŸ©é˜µï¼‰
    OD = cp.dot(concentrations, stain_matrix)
    normalized_RGB = convert_OD_to_RGB(OD.reshape(target_cp.shape))

    return cp.asnumpy(normalized_RGB)


# åŸºäºé¢„è®­ç»ƒCNNçš„ç‰¹å¾æå–
model = models.resnet50(pretrained=True).eval()
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])


def extract_cnn_features(image):
    """æå–CNNç‰¹å¾ï¼Œè¿”å›ä¸€ç»´ç‰¹å¾å‘é‡"""
    image = transform(image).unsqueeze(0)
    with torch.no_grad():
        features = model.conv1(image)
        features = model.bn1(features)
        features = model.relu(features)
        features = model.maxpool(features)
        features = model.layer1(features)  # æå–æµ…å±‚ç‰¹å¾
    return features.squeeze().numpy().flatten()


def preprocess_clinical_images(clinical_dir, reference_image, cache_file=None):
    """
    é¢„å¤„ç†æ‰€æœ‰ä¸´åºŠå›¾åƒï¼šæ ‡å‡†åŒ– + ç‰¹å¾æå–

    Args:
        clinical_dir: ä¸´åºŠå›¾åƒç›®å½•
        reference_image: å‚è€ƒå›¾åƒ (RGBæ ¼å¼)
        cache_file: ç‰¹å¾ç¼“å­˜æ–‡ä»¶è·¯å¾„ (å¯é€‰)

    Returns:
        (clinical_features, clinical_filenames)
        clinical_features: ä¸´åºŠå›¾åƒç‰¹å¾åˆ—è¡¨
        clinical_filenames: ä¸´åºŠå›¾åƒæ–‡ä»¶ååˆ—è¡¨
    """
    # æ£€æŸ¥ç¼“å­˜
    if cache_file and os.path.exists(cache_file):
        print(f"âœ… åŠ è½½ä¸´åºŠå›¾åƒç‰¹å¾ç¼“å­˜: {cache_file}")
        data = np.load(cache_file, allow_pickle=True)
        return data['features'], data['filenames']

    print("ğŸ”„ å¼€å§‹é¢„å¤„ç†ä¸´åºŠå›¾åƒ...")
    clinical_features = []
    clinical_filenames = []

    # å¤„ç†æ‰€æœ‰ä¸´åºŠå›¾åƒ
    for filename in tqdm(os.listdir(clinical_dir), desc="ä¸´åºŠå›¾åƒé¢„å¤„ç†"):
        clinical_img_path = os.path.join(clinical_dir, filename)
        clinical_img = cv2.imread(clinical_img_path)

        if clinical_img is None:
            continue

        # è½¬æ¢ä¸ºRGB
        clinical_img_rgb = cv2.cvtColor(clinical_img, cv2.COLOR_BGR2RGB)

        try:
            # æ ‡å‡†åŒ–
            normalized_image = macenko_normalize(reference_image, clinical_img_rgb)

            # ç‰¹å¾æå–
            features = extract_cnn_features(normalized_image)
            clinical_features.append(features)
            clinical_filenames.append(filename)

        except Exception as e:
            print(f"  è·³è¿‡ {filename}: {str(e)}")
            continue

    # ä¿å­˜ç¼“å­˜
    if cache_file:
        print(f"ğŸ’¾ ä¿å­˜ä¸´åºŠå›¾åƒç‰¹å¾ç¼“å­˜åˆ°: {cache_file}")
        np.savez_compressed(cache_file,
                            features=np.array(clinical_features),
                            filenames=clinical_filenames)

    return clinical_features, clinical_filenames


def main():
    # é…ç½®è·¯å¾„
    clinical_dir = "G:/data/segment/nonormlize/"
    predicted_img_PATH = "G:/data/hsa04151_ke_output/no_ke_patch/"
    output_file = r"G:\data\nonormlize_no_ke_prototype.txt"

    # å‚è€ƒå›¾åƒè·¯å¾„
    ref_path = 'E:/YUY/code/coding/coding/mycode/Review_Molecular_profile_prediction_GNN-main/1. Data_preprocessing/Ref.png'

    # æ£€æŸ¥è·¯å¾„
    if not os.path.exists(clinical_dir):
        raise FileNotFoundError(f"ä¸´åºŠå›¾åƒç›®å½•ä¸å­˜åœ¨: {clinical_dir}")
    if not os.path.exists(predicted_img_PATH):
        raise FileNotFoundError(f"é¢„æµ‹å›¾åƒç›®å½•ä¸å­˜åœ¨: {predicted_img_PATH}")
    if not os.path.exists(ref_path):
        raise FileNotFoundError(f"å‚è€ƒå›¾åƒä¸å­˜åœ¨: {ref_path}")

    # åŠ è½½å‚è€ƒå›¾åƒ
    reference_image = cv2.imread(ref_path)
    if reference_image is None:
        raise ValueError(f"æ— æ³•åŠ è½½å‚è€ƒå›¾åƒ: {ref_path}")
    reference_image = cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB)

    # é¢„å¤„ç†ä¸´åºŠå›¾åƒï¼ˆåªåšä¸€æ¬¡ï¼‰
    clinical_cache = os.path.join(os.path.dirname(output_file), "nonormlize_clinical_features.npz")
    clinical_features, clinical_filenames = preprocess_clinical_images(
        clinical_dir,
        reference_image,
        cache_file=clinical_cache
    )

    if len(clinical_features) == 0:  # æ­£ç¡®çš„æ£€æŸ¥æ–¹å¼
        raise ValueError("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•ä¸´åºŠå›¾åƒ")

    print(f"\nâœ… ä¸´åºŠå›¾åƒé¢„å¤„ç†å®Œæˆ: {len(clinical_features)} å¼ å›¾åƒ")
    print(f"  ç‰¹å¾ç»´åº¦: {clinical_features[0].shape[0]}")

    # è½¬æ¢ä¸ºNumPyæ•°ç»„ä»¥ä¾¿æ‰¹é‡è®¡ç®—
    clinical_features_array = np.array(clinical_features)

    # å¤„ç†æ‰€æœ‰é¢„æµ‹å›¾åƒ
    results = []
    mean_sim_list = []
    for filename_PRE in tqdm(os.listdir(predicted_img_PATH), desc="å¤„ç†é¢„æµ‹å›¾åƒ"):
        pred_img_path = os.path.join(predicted_img_PATH, filename_PRE)
        pred_img = cv2.imread(pred_img_path)

        if pred_img is None:
            continue

        # æå–é¢„æµ‹å›¾åƒç‰¹å¾
        pred_features = extract_cnn_features(pred_img)

        # è®¡ç®—ä¸æ‰€æœ‰ä¸´åºŠå›¾åƒçš„ç›¸ä¼¼åº¦ (æ‰¹é‡è®¡ç®—)
        similarities = cosine_similarity([pred_features], clinical_features_array)[0]

        # è®°å½•ç»“æœ
        results.append((filename_PRE, similarities.tolist()))

        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        mean_sim = np.mean(similarities)
        mean_sim_list.append(mean_sim)
        max_sim = np.max(similarities)
        best_match = clinical_filenames[np.argmax(similarities)]
        print(f"\n{filename_PRE} ç»“æœ:")
        print(f"  å¹³å‡ç›¸ä¼¼åº¦: {mean_sim:.4f}")
        print(f"  æœ€å¤§ç›¸ä¼¼åº¦: {max_sim:.4f} (åŒ¹é…: {best_match})")

    # ä¸€æ¬¡æ€§å†™å…¥æ‰€æœ‰ç»“æœ
    with open(output_file, 'w', encoding='utf-8') as f:
        for filename_PRE, similarities in results:
            # æ ¼å¼: é¢„æµ‹å›¾åƒæ–‡ä»¶å: [sim1, sim2, ...]
            f.write(f"{filename_PRE}: {[round(s, 6) for s in similarities]}\n")

    sort_mean_sim = sorted(mean_sim_list)
    print(f"\nâœ… å¹³å‡ç›¸ä¼¼åº¦æ’åºæƒ…å†µ:{sort_mean_sim}")

    print(f"\nâœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print(f"  å…±å¤„ç†: {len(results)} ä¸ªé¢„æµ‹å›¾åƒ")
    print(f"  ä¸´åºŠå›¾åƒç‰¹å¾ç¼“å­˜: {clinical_cache}")


if __name__ == "__main__":
    main()